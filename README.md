# OpenWebUI Generic External Ingestion Engine

Generic, production-ready **External Content Extraction Engine** for OpenWebUI.

This service replaces the default internal PDF parsing with a **robust, structure-aware ingestion pipeline** designed for complex tables (tariffs, matrices, multi-level headers, telecom grids, etc.).

It prevents common RAG hallucinations caused by:

- Lost table headers
- Flattened DataFrames
- Mixed tables in the same chunk
- Numeric columns without semantic labels

---

# âœ¨ Features

- âœ… Camelot (lattice â†’ stream) + pdfplumber fallback
- âœ… Automatic multi-row header reconstruction (generic)
- âœ… Table de-duplication via stable `hash_df`
- âœ… Row-level document emission (best RAG precision)
- âœ… Markdown snapshot fallback per table
- âœ… Automatic chunking with overlap
- âœ… PDF text fallback (pypdf)
- âœ… No document-specific hardcoding
- âœ… No per-PDF code modification required

---

# ğŸ§  Why This Exists

OpenWebUIâ€™s default PDF ingestion:

```

PDF â†’ text extraction â†’ chunking â†’ embedding

```

For complex tables, this causes:

- headers separated from data
- values without column meaning
- LLM â€œguessingâ€ semantics (e.g., inventing Fixe/Mobile labels)

This engine instead performs:

```

PDF â†’ structured table extraction â†’ header reconstruction â†’
row-level documents â†’ precise metadata â†’ embedding

````

Result: reliable answers for queries like:

> "Quels sont les tarifs concernant lâ€™Argentine ?"

---

# ğŸ“¦ Installation

## 1ï¸âƒ£ Clone repository

```bash
git clone https://github.com/your-org/openwebui-external-ingestion.git
cd openwebui-external-ingestion
````

## 2ï¸âƒ£ Create virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

## 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### System dependency (for Camelot lattice)

On Linux:

```bash
sudo apt install ghostscript
```

---

# ğŸ”§ requirements.txt

```txt
fastapi
uvicorn[standard]
pandas
tabulate
pypdf
camelot-py[cv]
pdfplumber
opencv-python
```

---

# ğŸš€ Run the Engine

```bash
export ENGINE_API_KEY="supersecret"
export PDF_PAGES="all"

uvicorn app:app --host 0.0.0.0 --port 8088
```

Test:

```bash
curl -X PUT "http://localhost:8088/process" \
  -H "Authorization: Bearer supersecret" \
  -H "Content-Type: application/pdf" \
  -H "X-Filename: tarifs.pdf" \
  --data-binary "@tarifs.pdf"
```

---

# ğŸ”Œ OpenWebUI Configuration

This engine works with OpenWebUIâ€™s **External Content Extraction Engine**.

## Option A â€” Docker (Recommended)

If OpenWebUI runs in Docker:

### docker-compose example

```yaml
services:
  openwebui:
    image: ghcr.io/open-webui/open-webui:latest
    environment:
      - CONTENT_EXTRACTION_ENGINE=external
      - EXTERNAL_DOCUMENT_LOADER_URL=http://ingestion-engine:8088
      - EXTERNAL_DOCUMENT_LOADER_API_KEY=supersecret
    depends_on:
      - ingestion-engine

  ingestion-engine:
    build: .
    environment:
      - ENGINE_API_KEY=supersecret
      - PDF_PAGES=all
      - MAX_DOC_CHARS=6000
      - OVERLAP_CHARS=800
    ports:
      - "8088:8088"
```

---

## Option B â€” OpenWebUI Local + Engine Local

If both run locally (no Docker):

Set OpenWebUI environment variables:

```bash
export CONTENT_EXTRACTION_ENGINE=external
export EXTERNAL_DOCUMENT_LOADER_URL=http://localhost:8088
export EXTERNAL_DOCUMENT_LOADER_API_KEY=supersecret
```

Restart OpenWebUI.

---

# ğŸ“‚ How It Works Internally

## 1ï¸âƒ£ Extraction Order

1. Camelot (lattice)
2. Camelot (stream)
3. pdfplumber

## 2ï¸âƒ£ Header Reconstruction

Automatically detects multi-line headers and rebuilds column names:

Example reconstructed column:

```
SMS envoyÃ© | Forfait 2â‚¬
```

No schema hardcoding.

## 3ï¸âƒ£ Row-Level Emission

If first column looks like an entity (e.g. country/destination):

Each row becomes a separate document:

```
Pays: Argentine
SMS envoyÃ© | Forfait 2â‚¬: 0,27 â‚¬
SMS envoyÃ© | Forfait Free 5G: 0,27 â‚¬
...
```

This dramatically improves retrieval precision.

## 4ï¸âƒ£ Table Snapshot

A Markdown snapshot is also stored for full-context retrieval.

---

# âš™ï¸ Environment Variables

| Variable                   | Default    | Description                    |
| -------------------------- | ---------- | ------------------------------ |
| ENGINE_API_KEY             | (required) | Must match OpenWebUI key       |
| PDF_PAGES                  | all        | Pages to parse                 |
| MAX_DOC_CHARS              | 6000       | Max document size              |
| OVERLAP_CHARS              | 800        | Chunk overlap                  |
| MAX_TEXT_PAGES             | 200        | Fallback text extraction limit |
| MAX_HEADER_ROWS            | 4          | Header detection depth         |
| CAMELOT_LATTICE_LINE_SCALE | 40         | Lattice tuning                 |
| CAMELOT_STREAM_EDGE_TOL    | 200        | Stream tuning                  |
| CAMELOT_STREAM_ROW_TOL     | 10         | Stream tuning                  |

---

# ğŸ” Troubleshooting

## âŒ â€œNo tables found in table areaâ€

Normal Camelot warning. Automatically handled.

## âŒ Wrong answers after engine update

Delete old Knowledge Base and re-upload PDFs.

Old chunks remain indexed otherwise.

## âŒ Scanned PDF

If text extraction is empty, PDF likely requires OCR.

---

# ğŸ§ª Recommended RAG Settings (OpenWebUI)

* Chunk size: 1000â€“1500 tokens
* Overlap: 200â€“300
* Recursive chunking: enabled
* Avoid aggressive separators

---

# ğŸ— Design Philosophy

* No per-document hacks
* No schema hardcoding
* Automatic structure detection
* RAG-first document design
* Production-safe behavior

---

# ğŸ“ˆ Result

Before:

```
Argentine | 0,27 | 0,27 | 1,05 | ...
```

LLM invents meaning.

After:

```
Pays: Argentine
SMS envoyÃ© | Forfait 2â‚¬: 0,27 â‚¬
...
```

LLM answers correctly without hallucination.

---

# ğŸ“œ License

MIT

---

# ğŸ§­ Pilotage d'innovation (visible et traÃ§able)

## 1) Documentation courte

Ce dÃ©pÃ´t contient dÃ©sormais les artefacts minimaux pour un pilotage lisible par une Ã©quipe produit, data et mÃ©tierÂ :

- un **README opÃ©rationnel** (installation, exÃ©cution, variables, limites),
- un **schÃ©ma de flux** dans `STATE.md`,
- un **cas d'usage critique** documentÃ© de bout en bout.

## 2) SchÃ©ma de progression (exploration â†’ service)

```mermaid
flowchart LR
    E[Exploration] --> POC[POC]
    POC --> PIL[Pilote]
    PIL --> STD[Standard]
    STD --> SVC[Service]

    E -. HypothÃ¨ses + faisabilitÃ© .-> POC
    POC -. Validation technique + valeur .-> PIL
    PIL -. Industrialisation + qualitÃ© .-> STD
    STD -. Exploitation + SLO/SLA .-> SVC
```

## 3) Code relanÃ§able (runbook minimal)

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

export ENGINE_API_KEY="supersecret"
export PDF_PAGES="all"
uvicorn app:app --host 0.0.0.0 --port 8088
```

## 4) Cas d'usage clair

> Ingestion d'un PDF tarifaire complexe pour rÃ©pondre Ã  une question mÃ©tier comme :
> **Â« Quels sont les tarifs concernant l'Argentine ? Â»**

Le pipeline conserve la structure tabulaire, Ã©met des documents au niveau ligne, puis retourne un JSON compatible OpenWebUI.

## 5) Valeur business Ã  suivre

Indicateurs proposÃ©s pour matÃ©rialiser la valeurÂ :

- **Temps gagnÃ©**Â : dÃ©lai d'onboarding d'un nouveau PDF avant/aprÃ¨s moteur externe.
- **Risque rÃ©duit**Â : taux d'hallucination ou d'erreur de rÃ©ponse sur jeux de questions de rÃ©fÃ©rence.
- **CoÃ»t Ã©vitÃ©**Â : baisse des reprises manuelles de correction des connaissances indexÃ©es.
- **CapacitÃ© crÃ©Ã©e**Â : volume de documents complexes ingÃ©rÃ©s sans adaptation spÃ©cifique.

---

# ğŸ¤ Contributions

Pull requests welcome.

Focus areas:

* OCR integration
* XLSX ingestion
* Advanced header detection
* SQL output mode
* Performance optimization for 100k+ row tables

---

```
---

# ğŸ—ºï¸ Project State Artifacts

A current project state file is available in `STATE.md`, including:

- Router / decision flow for the `/process` ingestion path
- A single critical end-to-end sequence test case

